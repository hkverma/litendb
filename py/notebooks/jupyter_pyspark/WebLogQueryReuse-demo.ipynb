{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cdd4de2-de36-4b81-95e5-06b54b381d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.27.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.3.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai->-r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 3)) (2023.3.23)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 1)) (1.26.14)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (22.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 1)) (1.3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75214f30-fffd-49f0-bdeb-e06cf3b9be04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started _liten_work_start=1 desc=Default work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, TimestampType\n",
    "import liten as ten\n",
    "os.environ['OPENAI_API_KEY']='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'\n",
    "tdb = ten.Database()\n",
    "spark = tdb.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8521d21f-c5b6-492d-b246-33f74a4e2a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdb.work.load('WebLogQuery-demo.ipynb')\n",
    "weblog_schema = StructType([ \\\n",
    "    StructField(\"IP\",StringType(),True), \\\n",
    "    StructField(\"Time\",TimestampType(),True), \\\n",
    "    StructField(\"URL\",StringType(),True), \\\n",
    "    StructField(\"Status\", IntegerType(), True)\n",
    "                           ])\n",
    "weblog_df = tdb.spark.read.format('csv').options(header='true').options(delimiter=',').options(timestampFormat='dd/MMM/yyyy:HH:mm:ss').schema(weblog_schema).load(\"weblog.csv\")\n",
    "weblog_df.createOrReplaceTempView(\"weblog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28302a9-9e97-49da-b401-e3311ef8aade",
   "metadata": {},
   "source": [
    "Summarize type of existing work items. It gives an idea if there is one useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5e53f4-e4de-4a07-bdf6-140301e038d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workitem 0: The given text is a Python notebook from Jupyter that installs required packages and libraries, imports necessary modules, and provides information about Liten database and its query capabilities. It also includes a command to stop a work item.\n",
      "\n",
      "Workitem 1: The given Python notebook is trying to load and analyze a sample web log file. It defines the schema for the file and reads it in as a DataFrame using Apache Spark. It then creates a temporary view of the DataFrame and prints its schema and the first five rows.\n",
      "\n",
      "Workitem 2: The Python notebook is using SQL queries to analyze a log file. It is counting the total number of log lines and determining the request counts which were redirected. The notebook is using the TDB library and Spark SQL to execute the queries.\n",
      "\n",
      "Workitem 3: The given python notebook in JSON format is trying to perform the following tasks:\n",
      "1. Starting a new interactive work and a new debug query.\n",
      "2. Describing a weblog file and listing the top three errors and failures encountered in it.\n",
      "3. Plotting the number of weblog requests before 2021 on a horizontal timeseries plot.\n",
      "\n",
      "Workitem 4: The python notebook is using TDB (unknown library) to perform some operations. It starts by creating a new interactive work and then runs a SQL query to count the number of rows in the weblog table where the status column has 404 errors. The output shows that there are 251 rows with 404 errors.\n",
      "\n",
      "Workitem 5: The python notebook is executing code to count the number of rows in a weblog table where the status column has 500 errors. It also includes a cell to start a new interactive work.\n",
      "\n",
      "Workitem 6: The python notebook is trying to troubleshoot connection timed out errors by running SQL queries on a weblog table. It first checks if any request timeout occurred and then generates an SQL query to count the number of rows where the Status column is equal to the HTTP status code for request timeout. Finally, it runs the SQL query and displays the count of rows that match the condition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdb.work.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3242d812-b839-43f4-bc1d-2e095ebdfcec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work 2 counts the total number of log lines and determines the request counts which were redirected. Therefore, Work 2 is the closest to the given work summary.\n"
     ]
    }
   ],
   "source": [
    "tdb.work.find_similar(\"Find the work item which counts the number of redirections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7cf3dd-5392-436d-a2c5-48eccb038068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdb.work.replay(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91387bdc-6df3-4191-91a2-f2f64be66f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped _liten_work_end=1\n",
      "Started _liten_work_start=2 desc=New interactive work\n",
      "Total number of log lines\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   15964|\n",
      "+--------+\n",
      "\n",
      "Request counts which were redirected\n",
      "+------+--------+\n",
      "|Status|count(1)|\n",
      "+------+--------+\n",
      "|   304|     658|\n",
      "|   302|    3498|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdb.work.new()\n",
    "print(f\"Total number of log lines\")\n",
    "cntDf = tdb.spark.sql(\"select count(*) from weblog\")\n",
    "cntDf.show()\n",
    "print(f\"Request counts which were redirected\")\n",
    "st3xxDf = tdb.spark.sql(\"SELECT Status, COUNT(*) FROM weblog WHERE Status LIKE '3%%' GROUP BY Status\")\n",
    "st3xxDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d04145-dc9c-4f6e-89f6-14d5342052b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workitem 0: There is no information regarding any request timeout in the provided output results.\n",
      "\n",
      "Workitem 1: Based on the provided output results, there is no information available about any request timeout. The output only shows the schema of the loaded weblog file and the first five rows of the dataframe.\n",
      "\n",
      "Workitem 2: There is no information provided in the output results about request timeout.\n",
      "\n",
      "Workitem 3: I'm sorry, but based on the provided data cells, there is no information about any request timeout or related output results. The provided data cells only contain information about starting a new work session, a markdown cell with instructions, a new debug query about weblogs, and the output result of that query.\n",
      "\n",
      "Workitem 4: There is no information provided in the given output results about any request timeout. The code and query executed in the notebook seem to be related to counting the number of rows in a database table where the Status column has 404 errors.\n",
      "\n",
      "Workitem 5: Based on the provided output, there is no information about any request timeout. The output only shows the execution of a new interactive work and the result of a SQL query to count the number of rows in a table where the Status column has 500 errors.\n",
      "\n",
      "Workitem 6: Based on the output results, it appears that there have been no request timeouts as the query did not find any rows with a Status value of 408.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdb.work.analyze(\"Tell me if there has been any request timeout based on the output results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bbb36f-92c0-4b17-976c-ea1de5ffa318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
